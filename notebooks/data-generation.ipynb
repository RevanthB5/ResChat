{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook scrapes the arXiv website for papers in the category \"cs.CV\" (Computer Vision), \"stat.ML\" / \"cs.LG\" (Machine Learning) and \"cs.AI\" (Artificial Intelligence). The papers are then saved in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T20:31:08.773167Z",
     "iopub.status.busy": "2024-10-30T20:31:08.772697Z",
     "iopub.status.idle": "2024-10-30T20:31:27.571304Z",
     "shell.execute_reply": "2024-10-30T20:31:27.569622Z",
     "shell.execute_reply.started": "2024-10-30T20:31:08.773120Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arxiv\n",
      "  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: requests~=2.32.0 in /opt/conda/lib/python3.10/site-packages (from arxiv) (2.32.3)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (2024.8.30)\n",
      "Downloading arxiv-2.1.3-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=461b7398343ae0a8b1aa17d43d3cbe1bdc9f5b79f6d051a0b8edc8867fe9444c\n",
      "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
      "Successfully installed arxiv-2.1.3 feedparser-6.0.11 sgmllib3k-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T20:31:27.574315Z",
     "iopub.status.busy": "2024-10-30T20:31:27.573871Z",
     "iopub.status.idle": "2024-10-30T20:31:28.159020Z",
     "shell.execute_reply": "2024-10-30T20:31:28.157900Z",
     "shell.execute_reply.started": "2024-10-30T20:31:27.574268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the arXiv website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining a list of keywords that we will use to query the arXiv API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T20:31:28.170966Z",
     "iopub.status.busy": "2024-10-30T20:31:28.169892Z",
     "iopub.status.idle": "2024-10-30T20:31:28.179308Z",
     "shell.execute_reply": "2024-10-30T20:31:28.178215Z",
     "shell.execute_reply.started": "2024-10-30T20:31:28.170914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "query_keywords = [\n",
    "    \"\\\"image segmentation\\\"\",\n",
    "    \"\\\"self-supervised learning\\\"\",\n",
    "    \"\\\"representation learning\\\"\",\n",
    "    \"\\\"image generation\\\"\",\n",
    "    \"\\\"object detection\\\"\",\n",
    "    \"\\\"transfer learning\\\"\",\n",
    "    \"\\\"transformers\\\"\",\n",
    "    \"\\\"adversarial training\",\n",
    "    \"\\\"generative adversarial networks\\\"\",\n",
    "    \"\\\"model compressions\\\"\",\n",
    "    \"\\\"image segmentation\\\"\",\n",
    "    \"\\\"few-shot learning\\\"\",\n",
    "    \"\\\"natural language\\\"\",\n",
    "    \"\\\"graph\\\"\",\n",
    "    \"\\\"colorization\\\"\",\n",
    "    \"\\\"depth estimation\\\"\",\n",
    "    \"\\\"point cloud\\\"\",\n",
    "    \"\\\"structured data\\\"\",\n",
    "    \"\\\"optical flow\\\"\",\n",
    "    \"\\\"reinforcement learning\\\"\",\n",
    "    \"\\\"super resolution\\\"\",\n",
    "    \"\\\"attention\\\"\",\n",
    "    \"\\\"tabular\\\"\",\n",
    "    \"\\\"unsupervised learning\\\"\",\n",
    "    \"\\\"semi-supervised learning\\\"\",\n",
    "    \"\\\"explainable\\\"\",\n",
    "    \"\\\"radiance field\\\"\",\n",
    "    \"\\\"decision tree\\\"\",\n",
    "    \"\\\"time series\\\"\",\n",
    "    \"\\\"molecule\\\"\",\n",
    "    \"\\\"large language models\\\"\",\n",
    "    \"\\\"llms\\\"\",\n",
    "    \"\\\"language models\\\"\",\n",
    "    \"\\\"image classification\\\"\",\n",
    "    \"\\\"document image classification\\\"\",\n",
    "    \"\\\"encoder\\\"\",\n",
    "    \"\\\"decoder\\\"\",\n",
    "    \"\\\"multimodal\\\"\",\n",
    "    \"\\\"multimodal deep learning\\\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we define a function that creates a search object using the given query. It sets the maximum number of results for each category to 6000 and sorts them by the last updated date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T20:31:28.180938Z",
     "iopub.status.busy": "2024-10-30T20:31:28.180571Z",
     "iopub.status.idle": "2024-10-30T20:31:28.194192Z",
     "shell.execute_reply": "2024-10-30T20:31:28.192983Z",
     "shell.execute_reply.started": "2024-10-30T20:31:28.180899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "client = arxiv.Client(num_retries=20, page_size=500)\n",
    "\n",
    "\n",
    "def query_with_keywords(query) -> tuple:\n",
    "    \"\"\"\n",
    "    Query the arXiv API for research papers based on a specific query and filter results by selected categories.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to be used for fetching research papers from arXiv.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: A tuple containing three lists - terms, titles, and abstracts of the filtered research papers.\n",
    "        \n",
    "            terms (list): A list of lists, where each inner list contains the categories associated with a research paper.\n",
    "            titles (list): A list of titles of the research papers.\n",
    "            abstracts (list): A list of abstracts (summaries) of the research papers.\n",
    "            urls (list): A list of URLs for the papers' detail page on the arXiv website.\n",
    "    \"\"\"\n",
    "    \n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=6000,\n",
    "        sort_by=arxiv.SortCriterion.LastUpdatedDate\n",
    "    )\n",
    "    \n",
    "    terms = []\n",
    "    titles = []\n",
    "    abstracts = []\n",
    "    urls = []\n",
    "\n",
    "    for res in tqdm(client.results(search), desc=query):\n",
    "        if res.primary_category in [\"cs.CV\", \"stat.ML\", \"cs.LG\", \"cs.AI\"]:\n",
    "            terms.append(res.categories)\n",
    "            titles.append(res.title)\n",
    "            abstracts.append(res.summary)\n",
    "            urls.append(res.entry_id)\n",
    "\n",
    "    return terms, titles, abstracts, urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T20:31:28.196256Z",
     "iopub.status.busy": "2024-10-30T20:31:28.195728Z",
     "iopub.status.idle": "2024-10-30T21:12:42.579648Z",
     "shell.execute_reply": "2024-10-30T21:12:42.578394Z",
     "shell.execute_reply.started": "2024-10-30T20:31:28.196203Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"image segmentation\": 4583it [01:02, 73.07it/s]\n",
      "\"self-supervised learning\": 0it [00:02, ?it/s]\n",
      "\"representation learning\": 6000it [02:03, 48.48it/s]\n",
      "\"image generation\": 4677it [01:53, 41.36it/s]\n",
      "\"object detection\": 6000it [01:37, 61.65it/s]\n",
      "\"transfer learning\": 6000it [01:31, 65.86it/s]\n",
      "\"transformers\": 6000it [01:24, 71.17it/s]\n",
      "\"adversarial training: 0it [00:02, ?it/s]\n",
      "\"generative adversarial networks\": 6000it [01:39, 60.54it/s]\n",
      "\"model compressions\": 1102it [00:16, 67.43it/s]\n",
      "\"image segmentation\": 4583it [00:58, 78.57it/s] \n",
      "\"few-shot learning\": 0it [00:03, ?it/s]\n",
      "\"natural language\": 6000it [01:22, 72.69it/s]\n",
      "\"graph\": 6000it [01:23, 71.90it/s]\n",
      "\"colorization\": 6000it [01:23, 71.90it/s]\n",
      "\"depth estimation\": 1930it [00:26, 73.80it/s]\n",
      "\"point cloud\": 6000it [01:34, 63.59it/s]\n",
      "\"structured data\": 2705it [00:46, 57.75it/s]\n",
      "\"optical flow\": 2025it [00:30, 66.85it/s]\n",
      "\"reinforcement learning\": 6000it [01:14, 80.51it/s]\n",
      "\"super resolution\": 4177it [01:01, 67.83it/s]\n",
      "\"attention\": 6000it [01:13, 82.03it/s]\n",
      "\"tabular\": 2545it [00:36, 70.60it/s]\n",
      "\"unsupervised learning\": 3481it [00:48, 71.95it/s]\n",
      "\"semi-supervised learning\": 0it [00:02, ?it/s]\n",
      "\"explainable\": 6000it [01:26, 69.08it/s]\n",
      "\"radiance field\": 1655it [00:26, 61.74it/s]\n",
      "\"decision tree\": 3338it [00:44, 75.25it/s]\n",
      "\"time series\": 6000it [01:34, 63.72it/s]\n",
      "\"molecule\": 6000it [01:28, 67.60it/s]\n",
      "\"large language models\": 6000it [01:44, 57.52it/s]\n",
      "\"llms\": 6000it [01:17, 76.98it/s]\n",
      "\"language models\": 6000it [02:03, 48.76it/s]\n",
      "\"image classification\": 6000it [01:27, 68.85it/s]\n",
      "\"document image classification\": 28it [00:02, 11.32it/s]\n",
      "\"encoder\": 6000it [01:24, 70.91it/s]\n",
      "\"decoder\": 6000it [01:14, 80.21it/s]\n",
      "\"multimodal\": 6000it [01:17, 76.93it/s]\n",
      "\"multimodal deep learning\": 133it [00:03, 42.83it/s]\n"
     ]
    }
   ],
   "source": [
    "all_titles = []\n",
    "all_abstracts = []\n",
    "all_terms = []\n",
    "all_urls = []\n",
    "\n",
    "for query in query_keywords:\n",
    "    terms, titles, abstracts, urls = query_with_keywords(query)\n",
    "    all_titles.extend(titles)\n",
    "    all_abstracts.extend(abstracts)\n",
    "    all_terms.extend(terms)\n",
    "    all_urls.extend(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a pandas.DataFrame object to store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T21:12:42.582649Z",
     "iopub.status.busy": "2024-10-30T21:12:42.582238Z",
     "iopub.status.idle": "2024-10-30T21:12:42.658436Z",
     "shell.execute_reply": "2024-10-30T21:12:42.657375Z",
     "shell.execute_reply.started": "2024-10-30T21:12:42.582606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "arxiv_data = pd.DataFrame({\n",
    "    'titles': all_titles,\n",
    "    'abstracts': all_abstracts,\n",
    "    'terms': all_terms,\n",
    "    'urls': all_urls\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we export the DataFrame to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T21:59:05.282611Z",
     "iopub.status.busy": "2024-10-30T21:59:05.281650Z",
     "iopub.status.idle": "2024-10-30T21:59:11.089815Z",
     "shell.execute_reply": "2024-10-30T21:59:11.088651Z",
     "shell.execute_reply.started": "2024-10-30T21:59:05.282562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "arxiv_data.to_csv('./data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T22:03:08.877100Z",
     "iopub.status.busy": "2024-10-30T22:03:08.876640Z",
     "iopub.status.idle": "2024-10-30T22:03:08.898956Z",
     "shell.execute_reply": "2024-10-30T22:03:08.897810Z",
     "shell.execute_reply.started": "2024-10-30T22:03:08.877060Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 58789 rows in the deduplicated dataset.\n"
     ]
    }
   ],
   "source": [
    "arxiv_data_1 = arxiv_data[~arxiv_data[\"titles\"].duplicated()]\n",
    "print(f\"There are {len(arxiv_data_1)} rows in the deduplicated dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T22:03:11.010881Z",
     "iopub.status.busy": "2024-10-30T22:03:11.010457Z",
     "iopub.status.idle": "2024-10-30T22:03:15.092202Z",
     "shell.execute_reply": "2024-10-30T22:03:15.091198Z",
     "shell.execute_reply.started": "2024-10-30T22:03:11.010839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "arxiv_data_1.to_csv('./filtered_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
