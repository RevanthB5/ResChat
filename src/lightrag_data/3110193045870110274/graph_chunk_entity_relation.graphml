<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d6" for="edge" attr.name="source_id" attr.type="string"/>
<key id="d5" for="edge" attr.name="keywords" attr.type="string"/>
<key id="d4" for="edge" attr.name="description" attr.type="string"/>
<key id="d3" for="edge" attr.name="weight" attr.type="double"/>
<key id="d2" for="node" attr.name="source_id" attr.type="string"/>
<key id="d1" for="node" attr.name="description" attr.type="string"/>
<key id="d0" for="node" attr.name="entity_type" attr.type="string"/>
<graph edgedefault="undirected"><node id="&quot;FACEBOOK RESEARCH&quot;">
  <data key="d0">"ORGANIZATION"</data>
  <data key="d1">"Facebook Research is an organization that provides code for masked region autoencoding, indicating its involvement in the development of the approach."</data>
  <data key="d2">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</node>
<node id="&quot;GITHUB&quot;">
  <data key="d0">"GEO"</data>
  <data key="d1">"GitHub is a platform where the code for R-MAE is provided, showing its role in hosting the project's repository."</data>
  <data key="d2">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</node>
<node id="&quot;MASKED AUTOENCODING (MAE)&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Masked Autoencoding (MAE) is a generative pre-training baseline that inspires the development of masked region autoencoding."</data>
  <data key="d2">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</node>
<node id="&quot;R-MAE&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"R-MAE is an approach that integrates masked region autoencoding with MAE, demonstrating improvements in pre-training datasets and downstream detection and segmentation benchmarks."</data>
  <data key="d2">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</node>
<node id="&quot;IMAGE REPRESENTATION&quot;">
  <data key="d0">"CONCEPT"</data>
  <data key="d1">"Image Representation refers to the process of learning representation of images, which is the goal of the approach."</data>
  <data key="d2">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</node>
<node id="&quot;SELF-SUPERVISED LEARNING&quot;">
  <data key="d0">"CONCEPT"</data>
  <data key="d1">"Self-Supervised Learning is a machine learning approach that involves learning from unlabeled data, which is used in the development of R-MAE."</data>
  <data key="d2">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</node>
<node id="&quot;REGIONS&quot;">
  <data key="d0">"CONCEPT"</data>
  <data key="d1">"Regions refer to groups of pixels in an image, which are used as a potential visual analogue of words for self-supervised image representation learning."</data>
  <data key="d2">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</node>
<node id="&quot;PIXELS&quot;">
  <data key="d0">"CONCEPT"</data>
  <data key="d1">"Pixels are the individual units of an image, which are grouped into regions for masked region autoencoding."</data>
  <data key="d2">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</node>
<node id="&quot;ARCHITECTURE&quot;">
  <data key="d0">"CONCEPT"</data>
  <data key="d1">"The architecture refers to the design of the model used for masked region autoencoding, which efficiently addresses the one-to-many mapping between images and regions."</data>
  <data key="d2">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</node>
<node id="&quot;DOWNSTREAM DETECTION&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Downstream Detection is a task that benefits from the pre-training of R-MAE, showing improved performance."</data>
  <data key="d2">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</node>
<node id="&quot;DOWNSTREAM SEGMENTATION&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Downstream Segmentation is a task that benefits from the pre-training of R-MAE, showing improved performance."</data>
  <data key="d2">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</node>
<node id="&quot;INTERACTIVE SEGMENTATION&quot;">
  <data key="d0">"EVENT"</data>
  <data key="d1">"Interactive Segmentation is a potential application of R-MAE, which unlocks its potential for interactive segmentation."</data>
  <data key="d2">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</node>
<edge source="&quot;FACEBOOK RESEARCH&quot;" target="&quot;R-MAE&quot;">
  <data key="d3">18.0</data>
  <data key="d4">"Facebook Research is the organization behind the development of R-MAE, providing the code for the approach."</data>
  <data key="d5">"development, code provision"</data>
  <data key="d6">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</edge>
<edge source="&quot;FACEBOOK RESEARCH&quot;" target="&quot;GITHUB&quot;">
  <data key="d3">10.0</data>
  <data key="d4">"GitHub hosts the repository for R-MAE, which is developed by Facebook Research."</data>
  <data key="d5">"platform, hosting"</data>
  <data key="d6">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</edge>
<edge source="&quot;MASKED AUTOENCODING (MAE)&quot;" target="&quot;R-MAE&quot;">
  <data key="d3">16.0</data>
  <data key="d4">"Masked Autoencoding (MAE) inspires the development of R-MAE, which integrates masked region autoencoding with MAE."</data>
  <data key="d5">"inspiration, integration"</data>
  <data key="d6">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</edge>
<edge source="&quot;R-MAE&quot;" target="&quot;ARCHITECTURE&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"The architecture is designed for R-MAE, which efficiently addresses the one-to-many mapping between images and regions."</data>
  <data key="d5">"design, efficient mapping"</data>
  <data key="d6">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</edge>
<edge source="&quot;R-MAE&quot;" target="&quot;DOWNSTREAM DETECTION&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"R-MAE demonstrates improved performance in Downstream Detection, which benefits from its pre-training."</data>
  <data key="d5">"performance, benefit"</data>
  <data key="d6">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</edge>
<edge source="&quot;R-MAE&quot;" target="&quot;DOWNSTREAM SEGMENTATION&quot;">
  <data key="d3">8.0</data>
  <data key="d4">"R-MAE demonstrates improved performance in Downstream Segmentation, which benefits from its pre-training."</data>
  <data key="d5">"performance, benefit"</data>
  <data key="d6">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</edge>
<edge source="&quot;R-MAE&quot;" target="&quot;INTERACTIVE SEGMENTATION&quot;">
  <data key="d3">9.0</data>
  <data key="d4">"R-MAE unlocks its potential for Interactive Segmentation, which is a potential application of the approach."</data>
  <data key="d5">"application, unlocking potential"</data>
  <data key="d6">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</edge>
<edge source="&quot;IMAGE REPRESENTATION&quot;" target="&quot;SELF-SUPERVISED LEARNING&quot;">
  <data key="d3">7.0</data>
  <data key="d4">"Image Representation is learned through Self-Supervised Learning, which is used in the development of R-MAE."</data>
  <data key="d5">"learning, representation"</data>
  <data key="d6">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</edge>
<edge source="&quot;REGIONS&quot;" target="&quot;PIXELS&quot;">
  <data key="d3">6.0</data>
  <data key="d4">"Regions are composed of Pixels, which are the individual units of an image."</data>
  <data key="d5">"composition, image units"</data>
  <data key="d6">chunk-02f9e2c2053047e90e593b3c8704f3be</data>
</edge>
</graph></graphml>