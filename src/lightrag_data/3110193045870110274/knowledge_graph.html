<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 500px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             
             #config {
                 float: left;
                 width: 400px;
                 height: 600px;
             }
             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        
            <div id="config"></div>
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#97c2fc", "description": "\"Facebook Research is an organization that provides code for masked region autoencoding, indicating its involvement in the development of the approach.\"", "entity_type": "\"ORGANIZATION\"", "font": {"color": "#000000"}, "id": "\"FACEBOOK RESEARCH\"", "label": "\"FACEBOOK RESEARCH\"", "shape": "dot", "size": 10, "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be"}, {"color": "#97c2fc", "description": "\"R-MAE is an approach that integrates masked region autoencoding with MAE, demonstrating improvements in pre-training datasets and downstream detection and segmentation benchmarks.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"R-MAE\"", "label": "\"R-MAE\"", "shape": "dot", "size": 10, "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be"}, {"color": "#97c2fc", "description": "\"GitHub is a platform where the code for R-MAE is provided, showing its role in hosting the project\u0027s repository.\"", "entity_type": "\"GEO\"", "font": {"color": "#000000"}, "id": "\"GITHUB\"", "label": "\"GITHUB\"", "shape": "dot", "size": 10, "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be"}, {"color": "#97c2fc", "description": "\"Masked Autoencoding (MAE) is a generative pre-training baseline that inspires the development of masked region autoencoding.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"MASKED AUTOENCODING (MAE)\"", "label": "\"MASKED AUTOENCODING (MAE)\"", "shape": "dot", "size": 10, "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be"}, {"color": "#97c2fc", "description": "\"The architecture refers to the design of the model used for masked region autoencoding, which efficiently addresses the one-to-many mapping between images and regions.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"ARCHITECTURE\"", "label": "\"ARCHITECTURE\"", "shape": "dot", "size": 10, "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be"}, {"color": "#97c2fc", "description": "\"Downstream Detection is a task that benefits from the pre-training of R-MAE, showing improved performance.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"DOWNSTREAM DETECTION\"", "label": "\"DOWNSTREAM DETECTION\"", "shape": "dot", "size": 10, "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be"}, {"color": "#97c2fc", "description": "\"Downstream Segmentation is a task that benefits from the pre-training of R-MAE, showing improved performance.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"DOWNSTREAM SEGMENTATION\"", "label": "\"DOWNSTREAM SEGMENTATION\"", "shape": "dot", "size": 10, "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be"}, {"color": "#97c2fc", "description": "\"Interactive Segmentation is a potential application of R-MAE, which unlocks its potential for interactive segmentation.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"INTERACTIVE SEGMENTATION\"", "label": "\"INTERACTIVE SEGMENTATION\"", "shape": "dot", "size": 10, "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be"}, {"color": "#97c2fc", "description": "\"Image Representation refers to the process of learning representation of images, which is the goal of the approach.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"IMAGE REPRESENTATION\"", "label": "\"IMAGE REPRESENTATION\"", "shape": "dot", "size": 10, "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be"}, {"color": "#97c2fc", "description": "\"Self-Supervised Learning is a machine learning approach that involves learning from unlabeled data, which is used in the development of R-MAE.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"SELF-SUPERVISED LEARNING\"", "label": "\"SELF-SUPERVISED LEARNING\"", "shape": "dot", "size": 10, "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be"}, {"color": "#97c2fc", "description": "\"Regions refer to groups of pixels in an image, which are used as a potential visual analogue of words for self-supervised image representation learning.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"REGIONS\"", "label": "\"REGIONS\"", "shape": "dot", "size": 10, "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be"}, {"color": "#97c2fc", "description": "\"Pixels are the individual units of an image, which are grouped into regions for masked region autoencoding.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"PIXELS\"", "label": "\"PIXELS\"", "shape": "dot", "size": 10, "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be"}]);
                  edges = new vis.DataSet([{"description": "\"Facebook Research is the organization behind the development of R-MAE, providing the code for the approach.\"", "from": "\"FACEBOOK RESEARCH\"", "keywords": "\"development, code provision\"", "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be", "to": "\"R-MAE\"", "width": 18.0}, {"description": "\"GitHub hosts the repository for R-MAE, which is developed by Facebook Research.\"", "from": "\"FACEBOOK RESEARCH\"", "keywords": "\"platform, hosting\"", "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be", "to": "\"GITHUB\"", "width": 10.0}, {"description": "\"Masked Autoencoding (MAE) inspires the development of R-MAE, which integrates masked region autoencoding with MAE.\"", "from": "\"MASKED AUTOENCODING (MAE)\"", "keywords": "\"inspiration, integration\"", "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be", "to": "\"R-MAE\"", "width": 16.0}, {"description": "\"The architecture is designed for R-MAE, which efficiently addresses the one-to-many mapping between images and regions.\"", "from": "\"R-MAE\"", "keywords": "\"design, efficient mapping\"", "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be", "to": "\"ARCHITECTURE\"", "width": 8.0}, {"description": "\"R-MAE demonstrates improved performance in Downstream Detection, which benefits from its pre-training.\"", "from": "\"R-MAE\"", "keywords": "\"performance, benefit\"", "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be", "to": "\"DOWNSTREAM DETECTION\"", "width": 8.0}, {"description": "\"R-MAE demonstrates improved performance in Downstream Segmentation, which benefits from its pre-training.\"", "from": "\"R-MAE\"", "keywords": "\"performance, benefit\"", "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be", "to": "\"DOWNSTREAM SEGMENTATION\"", "width": 8.0}, {"description": "\"R-MAE unlocks its potential for Interactive Segmentation, which is a potential application of the approach.\"", "from": "\"R-MAE\"", "keywords": "\"application, unlocking potential\"", "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be", "to": "\"INTERACTIVE SEGMENTATION\"", "width": 9.0}, {"description": "\"Image Representation is learned through Self-Supervised Learning, which is used in the development of R-MAE.\"", "from": "\"IMAGE REPRESENTATION\"", "keywords": "\"learning, representation\"", "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be", "to": "\"SELF-SUPERVISED LEARNING\"", "width": 7.0}, {"description": "\"Regions are composed of Pixels, which are the individual units of an image.\"", "from": "\"REGIONS\"", "keywords": "\"composition, image units\"", "source_id": "chunk-02f9e2c2053047e90e593b3c8704f3be", "to": "\"PIXELS\"", "width": 6.0}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {
    "configure": {
        "enabled": true,
        "filter": [
            "physics"
        ]
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};

                  


                  
                  // if this network requires displaying the configure window,
                  // put it in its div
                  options.configure["container"] = document.getElementById("config");
                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>