{
  "doc-7fe946787d7fd2c26a60368ea3cb0fad": {
    "content": "While much work has been devoted to understanding the implicit (and explicit)\nregularization of deep nonlinear networks in the supervised setting, this paper\nfocuses on unsupervised learning, i.e., autoencoders are trained with the\nobjective of reproducing the output from the input. We extend recent results\n[Jin et al. 2021] on unconstrained linear models and apply them to (1)\nnonlinear autoencoders and (2) constrained linear autoencoders, obtaining the\nfollowing two results: first, we show that the unsupervised setting by itself\ninduces strong additional regularization, i.e., a severe reduction in the\nmodel-capacity of the learned autoencoder: we derive that a deep nonlinear\nautoencoder cannot fit the training data more accurately than a linear\nautoencoder does if both models have the same dimensionality in their last\nhidden layer (and under a few additional assumptions). Our second contribution\nis concerned with the low-rank EDLAE model [Steck 2020], which is a linear\nautoencoder with a constraint on the diagonal of the learned low-rank\nparameter-matrix for improved generalization: we derive a closed-form\napproximation to the optimum of its non-convex training-objective, and\nempirically demonstrate that it is an accurate approximation across all\nmodel-ranks in our experiments on three well-known data sets."
  }
}