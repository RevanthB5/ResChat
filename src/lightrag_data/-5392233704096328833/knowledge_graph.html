<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 500px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             
             #loadingBar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width: 100%;
                 height: 500px;
                 background-color:rgba(200,200,200,0.8);
                 -webkit-transition: all 0.5s ease;
                 -moz-transition: all 0.5s ease;
                 -ms-transition: all 0.5s ease;
                 -o-transition: all 0.5s ease;
                 transition: all 0.5s ease;
                 opacity:1;
             }

             #bar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width:20px;
                 height:20px;
                 margin:auto auto auto auto;
                 border-radius:11px;
                 border:2px solid rgba(30,30,30,0.05);
                 background: rgb(0, 173, 246); /* Old browsers */
                 box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
             }

             #border {
                 position:absolute;
                 top:10px;
                 left:10px;
                 width:500px;
                 height:23px;
                 margin:auto auto auto auto;
                 box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
                 border-radius:10px;
             }

             #text {
                 position:absolute;
                 top:8px;
                 left:530px;
                 width:30px;
                 height:50px;
                 margin:auto auto auto auto;
                 font-size:22px;
                 color: #000000;
             }

             div.outerBorder {
                 position:relative;
                 top:400px;
                 width:600px;
                 height:44px;
                 margin:auto auto auto auto;
                 border:8px solid rgba(0,0,0,0.1);
                 background: rgb(252,252,252); /* Old browsers */
                 background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
                 background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
                 background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
                 background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
                 background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
                 background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
                 filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
                 border-radius:72px;
                 box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
             }
             

             
             #config {
                 float: left;
                 width: 400px;
                 height: 600px;
             }
             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
            <div id="loadingBar">
              <div class="outerBorder">
                <div id="text">0%</div>
                <div id="border">
                  <div id="bar"></div>
                </div>
              </div>
            </div>
        
        
            <div id="config"></div>
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#97c2fc", "description": "\"Marco Rudolph is one of the authors of the paper proposing Structuring Autoencoders and is affiliated with Leibniz Universit\u00e4t Hannover.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"MARCO RUDOLPH\"", "label": "\"MARCO RUDOLPH\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"Leibniz Universit\u00e4t Hannover is the institution where the authors are affiliated, contributing to the field of neural networks and data structuring.\"", "entity_type": "\"ORGANIZATION\"", "font": {"color": "#000000"}, "id": "\"LEIBNIZ UNIVERSIT\u00c4T HANNOVER\"", "label": "\"LEIBNIZ UNIVERSIT\u00c4T HANNOVER\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"Structuring Autoencoders (SAE) is a method proposed in the paper that aims to enhance traditional autoencoders with weak supervision to create a structured latent space.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"STRUCTURING AUTOENCODERS (SAE)\"", "label": "\"STRUCTURING AUTOENCODERS (SAE)\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"Bastian Wandt is a co-author of the paper on Structuring Autoencoders who contributes to the research associated with the proposal.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"BASTIAN WANDT\"", "label": "\"BASTIAN WANDT\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"Bodo Rosenhahn is a co-author of the research on Structuring Autoencoders and is affiliated with Leibniz Universit\u00e4t Hannover.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"BODO ROSENHAHN\"", "label": "\"BODO ROSENHAHN\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"MNIST is a benchmark image dataset used in the experiments to demonstrate the applicability of Structuring Autoencoders.\"\u003cSEP\u003e\"MNIST is a dataset used for training image processing systems, particularly in the context of recognizing handwritten digits.\"\u003cSEP\u003e\"MNIST is a dataset utilized in the evaluation of reconstruction capabilities by the autoencoder, focusing on handwritten digits.\"\u003cSEP\u003e\"MNIST is a well-known benchmark dataset consisting of handwritten digits, commonly used for training various image processing systems.\"\u003cSEP\u003e\"MNIST is a well-known benchmark dataset of handwritten digits, commonly used to train and evaluate machine learning models, particularly in image classification.\"\u003cSEP\u003e\"MNIST is a well-known dataset used in machine learning and computer vision for training various image processing systems.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"MNIST\"", "label": "\"MNIST\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8\u003cSEP\u003echunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a\u003cSEP\u003echunk-8540801279f57be4b29900eb965bc9b7\u003cSEP\u003echunk-e09194c38e45e88e7b2b1adf9be5a7c6\u003cSEP\u003echunk-25e488b3f3a1bc8c8ba9a749034b171e\u003cSEP\u003echunk-01919964963f385f6da15bcda957ea71"}, {"color": "#97c2fc", "description": "\"Fashion-MNIST is a benchmark dataset that contains images of clothing items classified into various categories, used for training neural networks.\"\u003cSEP\u003e\"Fashion-MNIST is a dataset introduced in 2017 that includes 60,000 training examples and 10,000 test examples of fashion items, divided into 10 classes.\"\u003cSEP\u003e\"Fashion-MNIST is a dataset serving as a replacement for MNIST, consisting of images of clothing items to improve the relevance of image classification tasks.\"\u003cSEP\u003e\"Fashion-MNIST is a dataset that extends the MNIST dataset by providing fashion products for training and evaluation purposes.\"\u003cSEP\u003e\"Fashion-MNIST is a dataset used for benchmarking machine learning models, similar to MNIST but with fashion items instead of digits.\"\u003cSEP\u003e\"Fashion-MNIST is a dataset used for image classification, focusing on fashion items, and is employed in various neural network experiments.\"\u003cSEP\u003e\"Fashion-MNIST is another benchmark image dataset utilized in the paper to show the effectiveness of the proposed method.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"FASHION-MNIST\"", "label": "\"FASHION-MNIST\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8\u003cSEP\u003echunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a\u003cSEP\u003echunk-a054a3e37bc1fcd86cb32715447f79a1\u003cSEP\u003echunk-8540801279f57be4b29900eb965bc9b7\u003cSEP\u003echunk-e09194c38e45e88e7b2b1adf9be5a7c6\u003cSEP\u003echunk-25e488b3f3a1bc8c8ba9a749034b171e\u003cSEP\u003echunk-01919964963f385f6da15bcda957ea71"}, {"color": "#97c2fc", "description": "\"DeepFashion2 is a dataset mentioned in the experiments of the paper, contributing to the validation of the Structuring Autoencoders.\u0027\u003cSEP\u003e\"DeepFashion2 is a dataset specifically designed for fashion-related image classification and analysis, highlighting challenging classification scenarios.\"\u003cSEP\u003e\"DeepFashion2 is a more complex fashion dataset that contains a variety of clothing items, utilized for advanced image processing and computer vision tasks.\"\u003cSEP\u003e\"DeepFashion2 is a recently published dataset featuring a diverse array of clothing items, utilized in evaluating the performance of classification algorithms.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"DEEPFASHION2\"", "label": "\"DEEPFASHION2\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8\u003cSEP\u003echunk-01919964963f385f6da15bcda957ea71\u003cSEP\u003echunk-a054a3e37bc1fcd86cb32715447f79a1\u003cSEP\u003echunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"3D Human Shapes is a dataset referenced in the paper to illustrate the application of the proposed method in categorizing human data.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"3D HUMAN SHAPES\"", "label": "\"3D HUMAN SHAPES\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"SAE (Structured Autoencoder) is a method developed to enhance traditional autoencoders by structuring the latent space according to class labels.\"\u003cSEP\u003e\"SAE, or Structuring Autoencoders, is a proposed method that improves data structuring, classification accuracy, and interpretable decision confidence in machine learning.\"\u003cSEP\u003e\"SAE, or Structuring Autoencoders, is a technology used for classification tasks that combines a reliable decision confidence mechanism with a smoothing effect on class separation.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"SAE\"", "label": "\"SAE\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e\u003cSEP\u003echunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a\u003cSEP\u003echunk-a054a3e37bc1fcd86cb32715447f79a1"}, {"color": "#97c2fc", "description": "\"HumanPose is likely a dataset or framework relevant to the study of human body shapes and poses in the context of machine learning and computer vision experiments.\"", "entity_type": "\"ORGANIZATION\"", "font": {"color": "#000000"}, "id": "\"HUMANPOSE\"", "label": "\"HUMANPOSE\"", "shape": "dot", "size": 10, "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"3D HumanPose is a data-driven event that serves as a dataset for training autoencoders, particularly in body shape and pose reconstruction.\"\u003cSEP\u003e\"3D HumanPose is a dataset containing 3D representations of human poses, utilized in evaluating autoencoder performance and classification accuracy.\"\u003cSEP\u003e\"3D HumanPose is a dataset created using SMPL to represent human models in different poses, with positions of 6890 vertices for training purposes.\"\u003cSEP\u003e\"3D HumanPose refers to a dataset specifically designed for analyzing and evaluating poses in 3D space, emphasizing human body shape recognition.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"3D HUMANPOSE\"", "label": "\"3D HUMANPOSE\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e\u003cSEP\u003echunk-01919964963f385f6da15bcda957ea71\u003cSEP\u003echunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a\u003cSEP\u003echunk-a054a3e37bc1fcd86cb32715447f79a1"}, {"color": "#97c2fc", "description": "\"Autoencoders are a type of neural network used for unsupervised learning through the encoding and decoding of data.\"\u003cSEP\u003e\"Autoencoders are a type of neural network used to learn efficient codings of unlabeled data for the purpose of dimensionality reduction and feature learning.\"\u003cSEP\u003e\"Autoencoders are neural networks designed to learn efficient representations of data by encoding input into a latent space and then decoding it back to its original format.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"AUTOENCODERS\"", "label": "\"AUTOENCODERS\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8\u003cSEP\u003echunk-a054a3e37bc1fcd86cb32715447f79a1\u003cSEP\u003echunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"Latent Space is a representation of compressed data from which original input can be reconstructed, used primarily in the context of autoencoders.\"\u003cSEP\u003e\"Latent Space is a representation of compressed data in machine learning, which helps to organize and structure data for effective processing.\"\u003cSEP\u003e\"Latent Space represents a compressed representation of the input data in which hidden structures can be analyzed and clustered more effectively.\"\u003cSEP\u003e\"Latent space is a representation learned by neural networks, where input data is transformed to capture relevant features and structures.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"LATENT SPACE\"", "label": "\"LATENT SPACE\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e\u003cSEP\u003echunk-01919964963f385f6da15bcda957ea71\u003cSEP\u003echunk-a054a3e37bc1fcd86cb32715447f79a1\u003cSEP\u003echunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"An Autoencoder is a type of artificial neural network used for unsupervised learning tasks, primarily for dimensionality reduction and feature extraction.\"\u003cSEP\u003e\"An Autoencoder is a type of neural network used for unsupervised learning, which learns to encode data in a lower-dimensional space and reconstruct it.\"\u003cSEP\u003e\"An autoencoder is a type of artificial neural network used to learn efficient representations of data, typically for dimensionality reduction or feature learning.\"\u003cSEP\u003e\"An autoencoder is a type of neural network used to learn efficient representations of data, typically for the purpose of dimensionality reduction or feature learning.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"AUTOENCODER\"", "label": "\"AUTOENCODER\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e\u003cSEP\u003echunk-01919964963f385f6da15bcda957ea71\u003cSEP\u003echunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a\u003cSEP\u003echunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"Support Vector Machines are supervised learning models used for classification and regression analysis in machine learning.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"SUPPORT VECTOR MACHINES\"", "label": "\"SUPPORT VECTOR MACHINES\"", "shape": "dot", "size": 10, "source_id": "chunk-01919964963f385f6da15bcda957ea71"}, {"color": "#97c2fc", "description": "\"Adversarial Autoencoders represent a class of techniques in machine learning that combine autoencoders with adversarial training to improve latent space structures.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"ADVERSARIAL AUTOENCODERS\"", "label": "\"ADVERSARIAL AUTOENCODERS\"", "shape": "dot", "size": 10, "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"Multidimensional Scaling is a statistical technique used to visualize the level of similarity of individual cases of a dataset.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"MULTIDIMENSIONAL SCALING\"", "label": "\"MULTIDIMENSIONAL SCALING\"", "shape": "dot", "size": 10, "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"Encoder refers to the model component that transforms input data into a latent space representation.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"ENCODER\"", "label": "\"ENCODER\"", "shape": "dot", "size": 10, "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"Neurons in this context refer to the artificial neurons used in neural networks, specifically with layers of 2048 and 256 in the described architecture.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"NEURONS\"", "label": "\"NEURONS\"", "shape": "dot", "size": 10, "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1"}, {"color": "#97c2fc", "description": "\"A Linear Classifier is a simple model that makes predictions based on a linear predictor function combining a set of weights.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"LINEAR CLASSIFIER\"", "label": "\"LINEAR CLASSIFIER\"", "shape": "dot", "size": 10, "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1"}, {"color": "#97c2fc", "description": "\"SVM, or Support Vector Machine, is a classification technique applied on the latent space to enhance accuracy compared to traditional neural networks.\"\u003cSEP\u003e\"SVM, or Support Vector Machine, is a traditional classifier used alongside SAE for predicting class membership probabilities and classifying data samples.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"SVM\"", "label": "\"SVM\"", "shape": "dot", "size": 10, "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a\u003cSEP\u003echunk-a054a3e37bc1fcd86cb32715447f79a1"}, {"color": "#97c2fc", "description": "\"Standard Autoencoders are traditional neural network architectures used for unsupervised learning that may struggle to reveal hidden data structures.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"STANDARD AUTOENCODERS\"", "label": "\"STANDARD AUTOENCODERS\"", "shape": "dot", "size": 10, "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1"}, {"color": "#97c2fc", "description": "\"Variational Autoencoders are advanced versions of autoencoders designed to learn complex distributions and effectively model latent spaces.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"VARIATIONAL AUTOENCODERS\"", "label": "\"VARIATIONAL AUTOENCODERS\"", "shape": "dot", "size": 10, "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1"}, {"color": "#97c2fc", "description": "\"Adversarial Autoencoder is a type of autoencoder that incorporates adversarial training to produce better data representations and performance.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"ADVERSARIAL AUTOENCODER\"", "label": "\"ADVERSARIAL AUTOENCODER\"", "shape": "dot", "size": 10, "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1"}, {"color": "#97c2fc", "description": "\"Decision Confidence refers to the certainty with which a model predicts a class label, distinguished by the quality of predictions made.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"DECISION CONFIDENCE\"", "label": "\"DECISION CONFIDENCE\"", "shape": "dot", "size": 10, "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1"}, {"color": "#97c2fc", "description": "\"Guided Labeling is a process within classification tasks to efficiently discover important samples with high uncertainty in the test set through intelligent selection.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"GUIDED LABELING\"", "label": "\"GUIDED LABELING\"", "shape": "dot", "size": 10, "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a"}, {"color": "#97c2fc", "description": "\"Markov Chain Neural Networks are advanced neural network architectures that may be combined with the proposed SAE to enhance learning and prediction tasks.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"MARKOV CHAIN NEURAL NETWORKS\"", "label": "\"MARKOV CHAIN NEURAL NETWORKS\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e"}, {"color": "#97c2fc", "description": "\"CNN, or Convolutional Neural Network, is a deep learning algorithm primarily used for processing structured grid data such as images.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"CNN\"", "label": "\"CNN\"", "shape": "dot", "size": 10, "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1"}, {"color": "#97c2fc", "description": "\"A. Carreira-Perpi\u00f1an is an author associated with research in computer vision and pattern recognition, contributing to the IEEE Conference.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"A. CARREIRA-PERPI\u00d1AN\"", "label": "\"A. CARREIRA-PERPI\u00d1AN\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"The IEEE Conference on Computer Vision and Pattern Recognition is a prominent event focused on advancements and research in computer vision, where significant findings are presented.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)\"", "label": "\"IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"The International Conference on Machine Learning is an influential event in the field of machine learning where researchers present their latest work, including denoising autoencoders and domain adaptation.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"INTERNATIONAL CONFERENCE ON MACHINE LEARNING (ICML)\"", "label": "\"INTERNATIONAL CONFERENCE ON MACHINE LEARNING (ICML)\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"R. Raziperchikolaei is a co-author contributing to the same research area as Carreira-Perpi\u00f1an, specifically in the field of computer vision.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"R. RAZIPERCHIKOLAEI\"", "label": "\"R. RAZIPERCHIKOLAEI\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"ACM, the Association for Computing Machinery, is an organization that publishes research and supports professionals in computing and information technology.\"", "entity_type": "\"ORGANIZATION\"", "font": {"color": "#000000"}, "id": "\"ACM\"", "label": "\"ACM\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"CoRR, Computation and Research Repository, is a repository where researchers publish papers and preprints, indicating its significance in the dissemination of research.\"", "entity_type": "\"ORGANIZATION\"", "font": {"color": "#000000"}, "id": "\"CORR\"", "label": "\"CORR\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"J. Engel collaborates on the hierarchical latent vector model research, focusing on music and structure modeling.\"\u003cSEP\u003e\"J. Engel is a researcher or author involved in the study of hierarchical latent vector models for music structure.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"J. ENGEL\"", "label": "\"J. ENGEL\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60\u003cSEP\u003echunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"C. Raffel is a researcher or author contributing to the same study on music structure.\"\u003cSEP\u003e\"C. Raffel is involved in developing hierarchical models for learning in music, indicating a focus on data-driven modeling.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"C. RAFFEL\"", "label": "\"C. RAFFEL\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60\u003cSEP\u003echunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"C. Hawthorne cooperates in the hierarchical latent vector model research, contributing to advancements in music structure analysis.\"\u003cSEP\u003e\"C. Hawthorne is a researcher associated with the hierarchical latent vector model for music.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"C. HAWTHORNE\"", "label": "\"C. HAWTHORNE\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60\u003cSEP\u003echunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"D. Eck is a co-author involved in hierarchical models for learning structure in music, showcasing expertise in machine learning applications.\"\u003cSEP\u003e\"D. Eck is a researcher involved in the study of long-term structure in music, collaborating with other authors.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"D. ECK\"", "label": "\"D. ECK\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60\u003cSEP\u003echunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"This event refers to a significant academic conference where research related to machine learning is presented and discussed.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING\"", "label": "\"PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"Stockholmsm\u00a8assan is the venue for the conference mentioned, located in Stockholm, Sweden.\"", "entity_type": "\"ORGANIZATION\"", "font": {"color": "#000000"}, "id": "\"STOCKHOLMSM\u00a8ASSAN\"", "label": "\"STOCKHOLMSM\u00a8ASSAN\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"Machine Learning Research is an academic publisher responsible for publishing the proceedings of the conference.\"", "entity_type": "\"ORGANIZATION\"", "font": {"color": "#000000"}, "id": "\"MACHINE LEARNING RESEARCH\"", "label": "\"MACHINE LEARNING RESEARCH\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"Weak Supervision is a method employed to enhance traditional autoencoders by providing minimal labeled data to guide the learning process.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"WEAK SUPERVISION\"", "label": "\"WEAK SUPERVISION\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"Structured Latent Space refers to a modified representation of data where semantic structures are organized meaningfully, facilitating better performance in various tasks.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"STRUCTURED LATENT SPACE\"", "label": "\"STRUCTURED LATENT SPACE\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"Data Structuring is the process of organizing data in a way that makes it easier to analyze, visualize, and interpret, improving its usability for different applications.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"DATA STRUCTURING\"", "label": "\"DATA STRUCTURING\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"Classification refers to the process of categorizing data points into predefined classes, which can be improved with better representations generated by Structuring Autoencoders.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"CLASSIFICATION\"", "label": "\"CLASSIFICATION\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"Reconstruction Error is a metric that indicates the difference between the original input data and its reconstruction, used to evaluate the performance of autoencoders.\"\u003cSEP\u003e\"Reconstruction Error measures the accuracy of the models in reconstructing input data from its compressed form, important in evaluating autoencoders.\"\u003cSEP\u003e\"Reconstruction error is a measure of how well an autoencoder can reproduce its original input, reflecting the performance of the model in learning representations.\"\u003cSEP\u003e\"Reconstruction error quantifies the difference between the original data and its reconstruction by an autoencoder, indicating model effectiveness.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"RECONSTRUCTION ERROR\"", "label": "\"RECONSTRUCTION ERROR\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8\u003cSEP\u003echunk-01919964963f385f6da15bcda957ea71\u003cSEP\u003echunk-25e488b3f3a1bc8c8ba9a749034b171e\u003cSEP\u003echunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"Latent Variables are the compressed representations of input data in the latent space, capturing essential features and structures.\"\u003cSEP\u003e\"Latent Variables are unobserved variables in a model that can explain the relationships between observed variables, often used in machine learning to reduce dimensionality.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"LATENT VARIABLES\"", "label": "\"LATENT VARIABLES\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8\u003cSEP\u003echunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"Distance Metric is a measure used to quantify how far apart two data points are in a given space, critical for organizing the learned representations in the latent space.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"DISTANCE METRIC\"", "label": "\"DISTANCE METRIC\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"HumanPose database is mentioned as a benchmark data source for visualizing latent spaces and evaluating the performance of autoencoders.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"HUMANPOSE DATABASE\"", "label": "\"HUMANPOSE DATABASE\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"Data Points are individual pieces of data that represent observations or features in a dataset, crucial for training models like autoencoders.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"DATA POINTS\"", "label": "\"DATA POINTS\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"Labeling Recommendations involve suggestions for which unlabeled data points should be annotated to improve model training, guided by the findings from the Structuring Autoencoders research.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"LABELING RECOMMENDATIONS\"", "label": "\"LABELING RECOMMENDATIONS\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"Morphing Between Classes refers to the ability to transform data points in the latent space from one class to another, demonstrating the flexibility of the structured representations.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"MORPHING BETWEEN CLASSES\"", "label": "\"MORPHING BETWEEN CLASSES\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"3D Human Pose refers to the various positions and orientations of a human body in three-dimensional space, which is relevant to the experiments described in the paper.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"3D HUMAN POSE\"", "label": "\"3D HUMAN POSE\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"Semantic Structure represents the deeper, meaningful relationships within data that the proposed autoencoder approach aims to uncover.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"SEMANTIC STRUCTURE\"", "label": "\"SEMANTIC STRUCTURE\"", "shape": "dot", "size": 10, "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8"}, {"color": "#97c2fc", "description": "\"The Structuring AutoEncoder is a machine learning model designed to organize and structure data representations in a latent space, maintaining distances between classes.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"STRUCTURING AUTOENCODER (SAE)\"", "label": "\"STRUCTURING AUTOENCODER (SAE)\"", "shape": "dot", "size": 10, "source_id": "chunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"Multidimensional Scaling is a statistical technique used for visualizing the level of similarity of individual datasets by reducing dimensionality while preserving distances.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"MULTIDIMENSIONAL SCALING (MDS)\"", "label": "\"MULTIDIMENSIONAL SCALING (MDS)\"", "shape": "dot", "size": 10, "source_id": "chunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"t-SNE, or t-distributed Stochastic Neighbor Embedding, is a machine learning algorithm particularly suited for visualizing high-dimensional data by reducing its dimensionality.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"T-SNE\"", "label": "\"T-SNE\"", "shape": "dot", "size": 10, "source_id": "chunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"UMAP is a dimension reduction technique that preserves more of the global structure of the data than t-SNE, making it useful for visualizing complex datasets.\"", "entity_type": "\"TECHNOLOGY\"", "font": {"color": "#000000"}, "id": "\"UNIFORM MANIFOLD APPROXIMATION AND PROJECTION (UMAP)\"", "label": "\"UNIFORM MANIFOLD APPROXIMATION AND PROJECTION (UMAP)\"", "shape": "dot", "size": 10, "source_id": "chunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"A loss function is a method of evaluating how well a specific algorithm models the given data, crucial for guiding the learning process in machine learning.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"LOSS FUNCTION\"", "label": "\"LOSS FUNCTION\"", "shape": "dot", "size": 10, "source_id": "chunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"Structural loss is a type of loss calculation used in the training of models like the SAE, which incorporates the structure of data as a factor in performance evaluation.\"\u003cSEP\u003e\"Structural loss refers to a type of loss function used to optimize model performance by imposing additional constraints during training.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"STRUCTURAL LOSS\"", "label": "\"STRUCTURAL LOSS\"", "shape": "dot", "size": 10, "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a\u003cSEP\u003echunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"Sparsely labeled data refers to datasets where only a small fraction of the input data is labeled, presenting challenges for traditional machine learning techniques.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"SPARSELY LABELED DATA\"", "label": "\"SPARSELY LABELED DATA\"", "shape": "dot", "size": 10, "source_id": "chunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"A specific dataset consisting of three-dimensional representations of human body shapes, used in machine learning applications to study shape analysis and classification.\"", "entity_type": "\"DATASET\"", "font": {"color": "#000000"}, "id": "\"3D MESHES OF HUMAN BODY SHAPES\"", "label": "\"3D MESHES OF HUMAN BODY SHAPES\"", "shape": "dot", "size": 10, "source_id": "chunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"Labeling efficiency refers to the effectiveness and economy with which data points in a dataset can be labeled, which is important in reducing time and cost in data preparation.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"LABELING EFFICIENCY\"", "label": "\"LABELING EFFICIENCY\"", "shape": "dot", "size": 10, "source_id": "chunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"Training Samples refer to the individual instances of data used to train machine learning models, essential for learning patterns and developing predictive capabilities.\"\u003cSEP\u003e\"Training samples are the data points used to train a machine learning model, crucial for its learning process and subsequent performance evaluation.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"TRAINING SAMPLES\"", "label": "\"TRAINING SAMPLES\"", "shape": "dot", "size": 10, "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6\u003cSEP\u003echunk-8540801279f57be4b29900eb965bc9b7"}, {"color": "#97c2fc", "description": "\"Convolutional Autoencoders are a variant of autoencoders that leverage convolutional layers to learn spatial hierarchies for image data.\"", "entity_type": "\"ORGANIZATION\"", "font": {"color": "#000000"}, "id": "\"CONVOLUTIONAL AUTOENCODERS\"", "label": "\"CONVOLUTIONAL AUTOENCODERS\"", "shape": "dot", "size": 10, "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"Loss Functions are mathematical functions used to measure how well a machine learning model performs, guiding the optimization process during training.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"LOSS FUNCTIONS\"", "label": "\"LOSS FUNCTIONS\"", "shape": "dot", "size": 10, "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"Mean Squared Error (MSE) is a commonly used loss function that calculates the average of the squares of errors between predicted and actual values.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"MEAN SQUARED ERROR (MSE)\"", "label": "\"MEAN SQUARED ERROR (MSE)\"", "shape": "dot", "size": 10, "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"Distance Matrix is a table that displays the distances between a set of points in a multi-dimensional space, often used in clustering and MDS applications.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"DISTANCE MATRIX\"", "label": "\"DISTANCE MATRIX\"", "shape": "dot", "size": 10, "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"Projection Matrix is used to project data into a lower-dimensional space, allowing for efficient analysis and visualization of patterns.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"PROJECTION MATRIX\"", "label": "\"PROJECTION MATRIX\"", "shape": "dot", "size": 10, "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"Singular Value Decomposition is a mathematical method used to factorize a matrix into its constituent elements, aiding in data dimensionality reduction.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"SINGULAR VALUE DECOMPOSITION\"", "label": "\"SINGULAR VALUE DECOMPOSITION\"", "shape": "dot", "size": 10, "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"Stress Minimization is a process used in MDS to reduce the discrepancy between the distances in the original space and the low-dimensional representation.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"STRESS MINIMIZATION\"", "label": "\"STRESS MINIMIZATION\"", "shape": "dot", "size": 10, "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"3D Body Shape Dataset is likely a collection of data points focusing on the shapes of human bodies in three dimensions, used for modeling and analysis in machine learning.\"\u003cSEP\u003e\"The 3D Body Shape Dataset consists of 3D models of human shapes, used for analysis in computer graphics and body modeling applications.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"3D BODY SHAPE DATASET\"", "label": "\"3D BODY SHAPE DATASET\"", "shape": "dot", "size": 10, "source_id": "chunk-01919964963f385f6da15bcda957ea71\u003cSEP\u003echunk-e09194c38e45e88e7b2b1adf9be5a7c6"}, {"color": "#97c2fc", "description": "\"Convergence refers to the process of reaching a consistent state during the training of machine learning models, particularly relevant for algorithms like autoencoders.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"CONVERGENCE\"", "label": "\"CONVERGENCE\"", "shape": "dot", "size": 10, "source_id": "chunk-01919964963f385f6da15bcda957ea71"}, {"color": "#97c2fc", "description": "\"An epoch refers to one complete pass through the entire training dataset during the training phase of a machine learning model.\"\u003cSEP\u003e\"Epoch denotes one complete cycle through the training dataset during the training of a machine learning model, critical for measuring performance.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"EPOCH\"", "label": "\"EPOCH\"", "shape": "dot", "size": 10, "source_id": "chunk-01919964963f385f6da15bcda957ea71\u003cSEP\u003echunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a"}, {"color": "#97c2fc", "description": "\"Data Augmentation is a technique used to increase the size and diversity of training datasets by applying transformations to the original data.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"DATA AUGMENTATION\"", "label": "\"DATA AUGMENTATION\"", "shape": "dot", "size": 10, "source_id": "chunk-01919964963f385f6da15bcda957ea71"}, {"color": "#97c2fc", "description": "\"The Training Set is the subset of data used to train a machine learning model, crucial for teaching the model its tasks.\"\u003cSEP\u003e\"The training set is a collection of labeled data used to train classification models for better accuracy and performance.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"TRAINING SET\"", "label": "\"TRAINING SET\"", "shape": "dot", "size": 10, "source_id": "chunk-01919964963f385f6da15bcda957ea71\u003cSEP\u003echunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a"}, {"color": "#97c2fc", "description": "\"The Test Set is a separate data subset used to evaluate the performance of a trained machine learning model, ensuring its effectiveness on unseen data.\"\u003cSEP\u003e\"The test set is an independent dataset used to evaluate the effectiveness of a trained model, ensuring that it generalizes well to unseen data.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"TEST SET\"", "label": "\"TEST SET\"", "shape": "dot", "size": 10, "source_id": "chunk-01919964963f385f6da15bcda957ea71\u003cSEP\u003echunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a"}, {"color": "#97c2fc", "description": "\"Image Data refers to visual information represented in the form of images, commonly used in tasks within computer vision and machine learning.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"IMAGE DATA\"", "label": "\"IMAGE DATA\"", "shape": "dot", "size": 10, "source_id": "chunk-01919964963f385f6da15bcda957ea71"}, {"color": "#97c2fc", "description": "\"Vector Data represents data points in a multi-dimensional space, used in machine learning for tasks such as classification and clustering.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"VECTOR DATA\"", "label": "\"VECTOR DATA\"", "shape": "dot", "size": 10, "source_id": "chunk-01919964963f385f6da15bcda957ea71"}, {"color": "#97c2fc", "description": "\"The picture refers to an image that is being analyzed to determine if it depicts a skirt or shorts, forming the basis for a classification task.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"THE PICTURE\"", "label": "\"THE PICTURE\"", "shape": "dot", "size": 10, "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a"}, {"color": "#97c2fc", "description": "\"Scores are numerical values derived from classification models, indicating the confidence in classifying items such as skirts or shorts.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"SCORES\"", "label": "\"SCORES\"", "shape": "dot", "size": 10, "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a"}, {"color": "#97c2fc", "description": "\"Prediction scores are values generated by classifiers which reflect the probabilities of an input belonging to a certain class.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"PREDICTION SCORES\"", "label": "\"PREDICTION SCORES\"", "shape": "dot", "size": 10, "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a"}, {"color": "#97c2fc", "description": "\"Class membership probability refers to the likelihood that a given sample belongs to a specific category, as predicted by a classifier.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"CLASS MEMBERSHIP PROBABILITY\"", "label": "\"CLASS MEMBERSHIP PROBABILITY\"", "shape": "dot", "size": 10, "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a"}, {"color": "#97c2fc", "description": "\"Reconstruction loss measures how well a model is able to recreate its input data, guiding improvements in training.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"RECONSTRUCTION LOSS\"", "label": "\"RECONSTRUCTION LOSS\"", "shape": "dot", "size": 10, "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a"}, {"color": "#97c2fc", "description": "\"A dataset is a structured collection of data, commonly used for training and evaluating machine learning models.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"DATASET\"", "label": "\"DATASET\"", "shape": "dot", "size": 10, "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a"}, {"color": "#97c2fc", "description": "\"Classification error indicates the percentage of misclassifications made by a model, reflecting its accuracy or performance in predicting classes.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"CLASSIFICATION ERROR\"", "label": "\"CLASSIFICATION ERROR\"", "shape": "dot", "size": 10, "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a"}, {"color": "#97c2fc", "description": "\"Critical samples are specific data points identified as particularly important for improving model accuracy during the training process.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"CRITICAL SAMPLES\"", "label": "\"CRITICAL SAMPLES\"", "shape": "dot", "size": 10, "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a"}, {"color": "#97c2fc", "description": "\"Numerical low reconstruction error is a measure indicating the quality of output from an autoencoder, demonstrating effective learning.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"NUMERICAL LOW RECONSTRUCTION ERROR\"", "label": "\"NUMERICAL LOW RECONSTRUCTION ERROR\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e"}, {"color": "#97c2fc", "description": "\"The deformation vector refers to a method for transitioning between classes in the latent space of an autoencoder, aiding in visual morphing.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"DEFORMATION VECTOR\"", "label": "\"DEFORMATION VECTOR\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e"}, {"color": "#97c2fc", "description": "\"Training data refers to the dataset used to train machine learning models, essential in shaping model accuracy and performance.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"TRAINING DATA\"", "label": "\"TRAINING DATA\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e"}, {"color": "#97c2fc", "description": "\"Class separation is the process implemented in machine learning where distinct categories in the data are differentiated in the model\u0027s learned representation.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"CLASS SEPARATION\"", "label": "\"CLASS SEPARATION\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e"}, {"color": "#97c2fc", "description": "\"Example reconstructions demonstrate the outputs generated by an autoencoder when processing various datasets, showcasing its capabilities.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"EXAMPLE RECONSTRUCTIONS\"", "label": "\"EXAMPLE RECONSTRUCTIONS\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e"}, {"color": "#97c2fc", "description": "\"Training cost refers to the resources and time invested in training machine learning models, highlighting the importance of efficient methods.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"TRAINING COST\"", "label": "\"TRAINING COST\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e"}, {"color": "#97c2fc", "description": "\"Subjective evaluation involves assessing the quality and performance of outputs based on personal judgment rather than numerical metrics.\"", "entity_type": "\"CONCEPT\"", "font": {"color": "#000000"}, "id": "\"SUBJECTIVE EVALUATION\"", "label": "\"SUBJECTIVE EVALUATION\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e"}, {"color": "#97c2fc", "description": "\"The guided labeling approach involves using distances in latent space to identify unlabeled data points with high classification uncertainty, assisting in efficient data labeling.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"GUIDED LABELING APPROACH\"", "label": "\"GUIDED LABELING APPROACH\"", "shape": "dot", "size": 10, "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e"}, {"color": "#97c2fc", "description": "\"M. Chen is an author cited in relation to marginalized denoising autoencoders, contributing to the research presented at the International Conference on Machine Learning.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"M. CHEN\"", "label": "\"M. CHEN\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"Z. Xu is a co-author associated with M. Chen on the work regarding domain adaptation and denoising autoencoders.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"Z. XU\"", "label": "\"Z. XU\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"K. Weinberger is a contributing author to the research on marginalized denoising autoencoders, indicating a focus on advancements in machine learning.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"K. WEINBERGER\"", "label": "\"K. WEINBERGER\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"F. Sha is a co-author involved in the study related to denoising autoencoders for domain adaptation, contributing to the field of machine learning.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"F. SHA\"", "label": "\"F. SHA\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"Y. Chen is an author noted for work on subspace clustering using low-rank constrained autoencoders, contributing to advancements in clustering methodologies.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"Y. CHEN\"", "label": "\"Y. CHEN\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"L. Zhang is a co-author of the work concerning subspace clustering, showcasing collaboration in research.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"L. ZHANG\"", "label": "\"L. ZHANG\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"Z. Yi is associated with subspace clustering research, highlighting contributions to data analysis techniques in machine learning.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"Z. YI\"", "label": "\"Z. YI\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"C. Donahue is an author involved in the semantically decomposing latent spaces for generative adversarial networks, indicating significant research contributions.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"C. DONAHUE\"", "label": "\"C. DONAHUE\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"A. Balsubramani is a co-author associated with research on generative adversarial networks, emphasizing the exploration of latent space decomposition.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"A. BALSUBRAMANI\"", "label": "\"A. BALSUBRAMANI\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"J. McAuley is a contributing author in the study of latent space decomposition in the context of generative models.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"J. MCAULEY\"", "label": "\"J. MCAULEY\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"Z. C. Lipton collaborates on research regarding generative adversarial networks, indicating involvement in cutting-edge machine learning research.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"Z. C. LIPTON\"", "label": "\"Z. C. LIPTON\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"Y. Ge is associated with research on DeepFashion2, a benchmark for clothing image analysis in various tasks.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"Y. GE\"", "label": "\"Y. GE\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"R. Zhang co-authors the DeepFashion2 benchmark research, contributing to the clothing image tasks.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"R. ZHANG\"", "label": "\"R. ZHANG\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"L. Wu is a co-author of the DeepFashion2 research, indicating active engagement in computer vision challenges.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"L. WU\"", "label": "\"L. WU\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"X. Wang is involved in DeepFashion2 research, emphasizing collaboration in fashion image analysis.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"X. WANG\"", "label": "\"X. WANG\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"X. Tang is also a contributor to the research oriented towards clothing images through the DeepFashion2 benchmark.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"X. TANG\"", "label": "\"X. TANG\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"P. Luo co-authors the work on DeepFashion2, demonstrating a focus on machine learning applications in fashion.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"P. LUO\"", "label": "\"P. LUO\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"S. Gra\u00dfhof is an author noted for research on expressions in relation to apathy, underscoring the intersection of psychology and computer vision.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"S. GRASSHOF\"", "label": "\"S. GRASSHOF\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"H. Ackermann contributes to the study of expressions related to apathy, indicating research in emotional recognition.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"H. ACKERMANN\"", "label": "\"H. ACKERMANN\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"S. S. Brandt collaborates on research examining the roots of expressions in human behavior.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"S. S. BRANDT\"", "label": "\"S. S. BRANDT\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"J. Ostermann is involved in the research focusing on expressions and social implications linked to apathy.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"J. OSTERMANN\"", "label": "\"J. OSTERMANN\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"G. E. Hinton is a renowned researcher in neural networks and data dimensionality reduction, contributing significantly to the field of deep learning.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"G. E. HINTON\"", "label": "\"G. E. HINTON\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"R. R. Salakhutdinov collaborates with Hinton on research related to reducing data dimensionality, indicating a strong partnership in AI research.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"R. R. SALAKHUTDINOV\"", "label": "\"R. R. SALAKHUTDINOV\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"D. P. Kingma is an author recognized for his work on variational autoencoders, a key concept in deep generative models.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"D. P. KINGMA\"", "label": "\"D. P. KINGMA\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"M. Welling is a co-author of the auto-encoding variational bayes paper, contributing to advancements in deep learning methodologies.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"M. WELLING\"", "label": "\"M. WELLING\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"J. B. Kruskal is noted for work in multidimensional scaling, contributing theoretical advancements to statistical analysis.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"J. B. KRUSKAL\"", "label": "\"J. B. KRUSKAL\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"T. D. Kulkarni is an author involved in research on deep convolutional inverse graphics networks, highlighting advancements in graphics processing.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"T. D. KULKARNI\"", "label": "\"T. D. KULKARNI\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"W. F. Whitney collaborates on the deep convolutional graphics network research, showcasing innovation in computer vision.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"W. F. WHITNEY\"", "label": "\"W. F. WHITNEY\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"P. Kohli is a co-author contributing to deep convolutional network research, indicating expertise in advanced machine learning techniques.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"P. KOHLI\"", "label": "\"P. KOHLI\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"J. Tenenbaum is a collaborator on deep convolutional graphics networks, indicating engagement in interdisciplinary research.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"J. TENENBAUM\"", "label": "\"J. TENENBAUM\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"Y. LeCun is a pioneer in neural network design and generalization, significantly impacting modern AI research.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"Y. LECUN\"", "label": "\"Y. LECUN\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"F. Li co-authors research on discriminative boosting for image clustering, indicating contributions to image analysis methodologies.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"F. LI\"", "label": "\"F. LI\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"H. Qiao is involved in research focusing on image clustering with autoencoders, showcasing advancements in computer vision.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"H. QIAO\"", "label": "\"H. QIAO\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"B. Zhang collaborates on the study regarding discriminative image clustering, indicating engagement with clustering techniques.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"B. ZHANG\"", "label": "\"B. ZHANG\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"H. Liu contributes to research on infinite ensemble methods for image clustering, emphasizing continuous innovation.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"H. LIU\"", "label": "\"H. LIU\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"M. Shao is a co-author involved in methods for image clustering, indicating expertise in data classification techniques.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"M. SHAO\"", "label": "\"M. SHAO\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"S. Li is associated with research on ensemble techniques for clustering, contributing to the design of advanced algorithms.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"S. LI\"", "label": "\"S. LI\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"Y. Fu collaborates on the infinite ensemble research in image clustering, showcasing dedication to enhancing machine learning.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"Y. FU\"", "label": "\"Y. FU\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"M. Loper is recognized for contributions to the SMPL model, impacting graphics and animation representation techniques.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"M. LOPER\"", "label": "\"M. LOPER\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"N. Mahmood co-authors the research on the SMPL model, highlighting collaboration in shape modeling.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"N. MAHMOOD\"", "label": "\"N. MAHMOOD\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"J. Romero is involved in developing the SMPL model for graphics representation, indicating active engagement in visual computing.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"J. ROMERO\"", "label": "\"J. ROMERO\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"G. Pons-Moll collaborates on the SMPL model research, contributing to the intersection of graphics and machine learning.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"G. PONS-MOLL\"", "label": "\"G. PONS-MOLL\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"M. J. Black is a co-author associated with the SMPL model work, indicating contributions to human shape modeling research.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"M. J. BLACK\"", "label": "\"M. J. BLACK\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"A. Makhzani is an author recognized for research on adversarial autoencoders, contributing to generative modeling techniques.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"A. MAKHZANI\"", "label": "\"A. MAKHZANI\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"J. Shlens is a collaborator on adversarial autoencoder research, indicating contributions to innovative machine learning techniques.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"J. SHLENS\"", "label": "\"J. SHLENS\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"N. Jaitly works on adversarial autoencoders, showcasing research into novel data generation methods.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"N. JAITLY\"", "label": "\"N. JAITLY\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"I. Goodfellow is known for pioneering the concept of generative adversarial networks, significantly impacting generative modeling.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"I. GOODFELLOW\"", "label": "\"I. GOODFELLOW\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"L. McInnes contributes to the development and publication of UMAP, enhancing dimensionality reduction techniques.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"L. MCINNES\"", "label": "\"L. MCINNES\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"J. Healy collaborates in the UMAP research initiative, furthering advancements in data visualization and dimensionality reduction.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"J. HEALY\"", "label": "\"J. HEALY\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"A. Roberts co-authors the hierarchical latent vector model work, demonstrating contributions to long-term structure learning.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"A. ROBERTS\"", "label": "\"A. ROBERTS\"", "shape": "dot", "size": 10, "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60"}, {"color": "#97c2fc", "description": "\"P. H. Sch\u00f6nemann is an author known for publishing work related to the orthogonal Procrustes problem in psychometrics.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"P. H. SCH\u00d6NEMANN\"", "label": "\"P. H. SCH\u00d6NEMANN\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"K. Simonyan is a researcher who contributed to the study of very deep convolutional networks for large-scale image recognition.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"K. SIMONYAN\"", "label": "\"K. SIMONYAN\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"A. Zisserman is a co-author with K. Simonyan on research related to deep convolutional networks.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"A. ZISSERMAN\"", "label": "\"A. ZISSERMAN\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"C. Song is a researcher associated with auto-encoder based data clustering in computer vision applications.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"C. SONG\"", "label": "\"C. SONG\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"F. Liu is a co-author of the study on data clustering using auto-encoders.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"F. LIU\"", "label": "\"F. LIU\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"Y. Huang is a collaborator in the auto-encoder based clustering research.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"Y. HUANG\"", "label": "\"Y. HUANG\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"L. Wang is an author contributing to the research on data clustering with auto-encoders.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"L. WANG\"", "label": "\"L. WANG\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"T. Tan is involved in the research on auto-encoder based data clustering, contributing as a co-author.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"T. TAN\"", "label": "\"T. TAN\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"L. van der Maaten is a researcher known for contributions to t-SNE algorithms and visualizing high-dimensional data.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"L. VAN DER MAATEN\"", "label": "\"L. VAN DER MAATEN\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"G. Hinton is a co-author with L. van der Maaten in work on visualizing high-dimensional data using t-SNE.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"G. HINTON\"", "label": "\"G. HINTON\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"V. N. Vapnik is a notable figure in pattern recognition theory, known for his significant contributions.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"V. N. VAPNIK\"", "label": "\"V. N. VAPNIK\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"A. Y. Chervonenkis is a co-author with V. N. Vapnik on the theory of pattern recognition.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"A. Y. CHERVONENKIS\"", "label": "\"A. Y. CHERVONENKIS\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"P. Vincent is a researcher who has published studies on stacked denoising autoencoders with significant implications in deep learning.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"P. VINCENT\"", "label": "\"P. VINCENT\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"H. Larochelle is a co-author of P. Vincent\u0027s research on learning useful representations in deep networks.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"H. LAROCHELLE\"", "label": "\"H. LAROCHELLE\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"I. Lajoie is involved in the research on stacked denoising autoencoders alongside P. Vincent and colleagues.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"I. LAJOIE\"", "label": "\"I. LAJOIE\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"Y. Bengio is a prominent researcher in machine learning, co-authoring studies on stacked denoising autoencoders.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"Y. BENGIO\"", "label": "\"Y. BENGIO\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"P.-A. Manzagol is a contributor to the research on learning representations in deep networks with a local denoising criterion.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"P.-A. MANZAGOL\"", "label": "\"P.-A. MANZAGOL\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"B. Wandt is a researcher who studied adversarial reprojection networks for 3D human pose estimation, contributing to weakly supervised training methods.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"B. WANDT\"", "label": "\"B. WANDT\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"B. Rosenhahn is a co-author with B. Wandt in research focused on 3D human pose estimation and adversarial networks.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"B. ROSENHAHN\"", "label": "\"B. ROSENHAHN\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"H. Xiao is associated with the development of the Fashion-MNIST dataset aimed at benchmarking machine learning algorithms.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"H. XIAO\"", "label": "\"H. XIAO\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"K. Rasul is a contributor to the Fashion-MNIST project, which serves as a novel image dataset for benchmarking.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"K. RASUL\"", "label": "\"K. RASUL\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"R. Vollgraf is involved in the Fashion-MNIST project, contributing to the creation of the dataset for machine learning.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"R. VOLLGRAF\"", "label": "\"R. VOLLGRAF\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"M. Y. Yang is a researcher focused on video event recognition and anomaly detection using Gaussian process models.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"M. Y. YANG\"", "label": "\"M. Y. YANG\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"W. Liao collaborates in research on video event recognition and anomaly detection techniques.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"W. LIAO\"", "label": "\"W. LIAO\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"Y. Cao is involved in the study on detecting video events and anomalies, working with M. Y. Yang and team.\"", "entity_type": "\"PERSON\"", "font": {"color": "#000000"}, "id": "\"Y. CAO\"", "label": "\"Y. CAO\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"This event refers to the journal where research related to video event recognition and processing is published.\"", "entity_type": "\"EVENT\"", "font": {"color": "#000000"}, "id": "\"PHOTOGRAMMETRIC ENGINEERING \u0026 REMOTE SENSING\"", "label": "\"PHOTOGRAMMETRIC ENGINEERING \u0026 REMOTE SENSING\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"Lawrence Erlbaum Associates is a publisher known for its contributions to literature in psychology and machine learning.\"", "entity_type": "\"ORGANIZATION\"", "font": {"color": "#000000"}, "id": "\"LAWRENCE ERLBAUM ASSOCIATES\"", "label": "\"LAWRENCE ERLBAUM ASSOCIATES\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"Hillsdale, New Jersey is a location that is associated with the publications by Lawrence Erlbaum Associates.\"", "entity_type": "\"GEO\"", "font": {"color": "#000000"}, "id": "\"HILLSDALE, NEW JERSEY\"", "label": "\"HILLSDALE, NEW JERSEY\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}, {"color": "#97c2fc", "description": "\"London is another location associated with the publications of Lawrence Erlbaum Associates.\"", "entity_type": "\"GEO\"", "font": {"color": "#000000"}, "id": "\"LONDON\"", "label": "\"LONDON\"", "shape": "dot", "size": 10, "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c"}]);
                  edges = new vis.DataSet([{"description": "\"Marco Rudolph is affiliated with Leibniz Universit\u00e4t Hannover, the institution behind the research on Structuring Autoencoders.\"", "from": "\"MARCO RUDOLPH\"", "keywords": "\"affiliation, research institution\"", "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8", "to": "\"LEIBNIZ UNIVERSIT\u00c4T HANNOVER\"", "width": 9.0}, {"description": "\"Marco Rudolph is one of the authors proposing the Structuring Autoencoders method detailing its functionality and benefits.\"", "from": "\"MARCO RUDOLPH\"", "keywords": "\"research proposal, author\"", "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8", "to": "\"STRUCTURING AUTOENCODERS (SAE)\"", "width": 10.0}, {"description": "\"Bastian Wandt is affiliated with Leibniz Universit\u00e4t Hannover and collaborates on the research regarding Structuring Autoencoders.\"", "from": "\"BASTIAN WANDT\"", "keywords": "\"affiliation, research institution\"", "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8", "to": "\"LEIBNIZ UNIVERSIT\u00c4T HANNOVER\"", "width": 9.0}, {"description": "\"Bastian Wandt contributes as a co-author to the proposal and validation of Structuring Autoencoders in the paper.\"", "from": "\"BASTIAN WANDT\"", "keywords": "\"research proposal, author\"", "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8", "to": "\"STRUCTURING AUTOENCODERS (SAE)\"", "width": 10.0}, {"description": "\"Bodo Rosenhahn is associated with Leibniz Universit\u00e4t Hannover, contributing to the research on Structuring Autoencoders.\"", "from": "\"BODO ROSENHAHN\"", "keywords": "\"affiliation, research institution\"", "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8", "to": "\"LEIBNIZ UNIVERSIT\u00c4T HANNOVER\"", "width": 9.0}, {"description": "\"Bodo Rosenhahn also co-authors the proposal detailing the Structuring Autoencoders initiative.\"", "from": "\"BODO ROSENHAHN\"", "keywords": "\"research proposal, author\"", "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8", "to": "\"STRUCTURING AUTOENCODERS (SAE)\"", "width": 10.0}, {"description": "\"Structuring Autoencoders (SAE) is applied to the MNIST dataset to demonstrate its effectiveness in data representation.\"", "from": "\"STRUCTURING AUTOENCODERS (SAE)\"", "keywords": "\"application, data representation\"", "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8", "to": "\"MNIST\"", "width": 8.0}, {"description": "\"The methodology of Structuring Autoencoders (SAE) is tested on the Fashion-MNIST dataset, showing its general applicability.\"", "from": "\"STRUCTURING AUTOENCODERS (SAE)\"", "keywords": "\"application, data validation\"", "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8", "to": "\"FASHION-MNIST\"", "width": 8.0}, {"description": "\"The DeepFashion2 dataset is used in exploring the applicability of Structuring Autoencoders in fashion-related data tasks.\"", "from": "\"STRUCTURING AUTOENCODERS (SAE)\"", "keywords": "\"application, data validation\"", "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8", "to": "\"DEEPFASHION2\"", "width": 8.0}, {"description": "\"3D Human Shapes dataset illustrates the utility of Structuring Autoencoders in analyzing complex human shape data.\"", "from": "\"STRUCTURING AUTOENCODERS (SAE)\"", "keywords": "\"application, data analysis\"", "source_id": "chunk-fdfce24a4a26f0d1ba1c968c854375b8", "to": "\"3D HUMAN SHAPES\"", "width": 8.0}, {"description": "\"SAE has been tested and trained using the MNIST dataset to evaluate its performance in recognizing handwritten digits.\"\u003cSEP\u003e\"The SAE shows its effectiveness in reconstructing data from the MNIST dataset, demonstrating its application in digit recognition tasks.\"\u003cSEP\u003e\"The Structuring AutoEncoder employs the MNIST dataset during experiments to validate the model\u0027s ability to structure data based on given classes.\"", "from": "\"MNIST\"", "keywords": "\"dataset testing, performance evaluation\"\u003cSEP\u003e\"method application, reconstruction\"\u003cSEP\u003e\"validation, performance\"", "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e\u003cSEP\u003echunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a\u003cSEP\u003echunk-8540801279f57be4b29900eb965bc9b7", "to": "\"SAE\"", "width": 24.0}, {"description": "\"HumanPose is likely being compared with MNIST in experiments to evaluate how well each dataset performs under various machine learning models.\"", "from": "\"MNIST\"", "keywords": "\"comparison, benchmarking\"", "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6", "to": "\"HUMANPOSE\"", "width": 6.0}, {"description": "\"Both MNIST and Fashion-MNIST are benchmark datasets utilized for training and evaluating machine learning models, specifically in image processing tasks.\"\u003cSEP\u003e\"Both MNIST and Fashion-MNIST are datasets used for benchmarking and comparisons in model performance within machine learning.\".\"", "from": "\"MNIST\"", "keywords": "\"benchmark datasets, image processing\"\u003cSEP\u003e\"benchmarking, dataset comparison\"", "source_id": "chunk-01919964963f385f6da15bcda957ea71\u003cSEP\u003echunk-e09194c38e45e88e7b2b1adf9be5a7c6", "to": "\"FASHION-MNIST\"", "width": 16.0}, {"description": "\"Fashion-MNIST dataset serves as a benchmark for testing the effectiveness of SAE in achieving better classification outcomes.\"\u003cSEP\u003e\"SAE has been adapted and tested on the Fashion-MNIST dataset to extend its application to clothing item recognition tasks.\"\u003cSEP\u003e\"Similar to MNIST, SAE is applied to Fashion-MNIST to assess its performance in reconstructing fashion-related images.\"\u003cSEP\u003e\"The Structuring AutoEncoder is applied to the Fashion-MNIST dataset, demonstrating efficacious performance in classification tasks.\"", "from": "\"FASHION-MNIST\"", "keywords": "\"application extension, dataset testing\"\u003cSEP\u003e\"application, performance\"\u003cSEP\u003e\"dataset evaluation, performance improvement\"\u003cSEP\u003e\"method application, reconstruction\"", "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e\u003cSEP\u003echunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a\u003cSEP\u003echunk-a054a3e37bc1fcd86cb32715447f79a1\u003cSEP\u003echunk-8540801279f57be4b29900eb965bc9b7", "to": "\"SAE\"", "width": 33.0}, {"description": "\"Fashion-MNIST provides a simpler challenge compared to DeepFashion2, which is used for more complex image recognition tasks.\"", "from": "\"FASHION-MNIST\"", "keywords": "\"dataset complexity, computer vision\"", "source_id": "chunk-01919964963f385f6da15bcda957ea71", "to": "\"DEEPFASHION2\"", "width": 7.0}, {"description": "\"DeepFashion2 dataset is utilized to highlight the strengths of SAE in providing meaningful prediction scores and improving classification tasks.\"\u003cSEP\u003e\"The Structuring AutoEncoder outperforms other classifiers when applied to the DeepFashion2 dataset, showing its effectiveness in real-world applications.\"", "from": "\"DEEPFASHION2\"", "keywords": "\"application, performance\"\u003cSEP\u003e\"classification effectiveness, dataset challenge\"", "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1\u003cSEP\u003echunk-8540801279f57be4b29900eb965bc9b7", "to": "\"SAE\"", "width": 18.0}, {"description": "\"3D HumanPose dataset provides data in vectorial form similar to the challenges posed by DeepFashion2, used for advanced modeling tasks.\"", "from": "\"DEEPFASHION2\"", "keywords": "\"data variety, modeling challenges\"", "source_id": "chunk-01919964963f385f6da15bcda957ea71", "to": "\"3D HUMANPOSE\"", "width": 6.0}, {"description": "\"Latent Space is a critical component of Autoencoders, facilitating the compression and reconstruction of input data.\".\"", "from": "\"AUTOENCODERS\"", "keywords": "\"data representation, functionality\"", "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1", "to": "\"LATENT SPACE\"", "width": 9.0}, {"description": "\"Autoencoders can be used to preprocess data for Support Vector Machines, enhancing the classification task using lower-dimensional representations.\"", "from": "\"AUTOENCODER\"", "keywords": "\"data preprocessing, machine learning\"", "source_id": "chunk-01919964963f385f6da15bcda957ea71", "to": "\"SUPPORT VECTOR MACHINES\"", "width": 8.0}, {"description": "\"Adversarial Autoencoders may utilize Multidimensional Scaling to arrange data points in an effective Latent Space representation.\"", "from": "\"ADVERSARIAL AUTOENCODERS\"", "keywords": "\"data visualization, technique integration\"", "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6", "to": "\"MULTIDIMENSIONAL SCALING\"", "width": 7.0}, {"description": "\"The Encoder is responsible for projecting data into the Latent Space, facilitating the representation of data in a compressed format.\"", "from": "\"ENCODER\"", "keywords": "\"data transformation, representation\"", "source_id": "chunk-e09194c38e45e88e7b2b1adf9be5a7c6", "to": "\"LATENT SPACE\"", "width": 9.0}, {"description": "\"Neurons are employed in defining the architecture of the network that processes data in the Latent Space.\".\"", "from": "\"LATENT SPACE\"", "keywords": "\"data processing, network architecture\"", "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1", "to": "\"NEURONS\"", "width": 7.0}, {"description": "\"Linear Classifier models leverage the structured representations in the Latent Space for improved classification accuracy.\".\"", "from": "\"LATENT SPACE\"", "keywords": "\"classification, accuracy enhancement\"", "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1", "to": "\"LINEAR CLASSIFIER\"", "width": 8.0}, {"description": "\"3D HumanPose dataset is evaluated using SAE methodologies, demonstrating the effectiveness of SAE in handling complex data structures.\"\u003cSEP\u003e\"SAE is adapted for the 3D HumanPose dataset to recognize complex human poses through effective classification methods.\"\u003cSEP\u003e\"The SAE method is utilized for reconstructing 3D HumanPose data, indicating its direct role in improving pose-related tasks.\"", "from": "\"3D HUMANPOSE\"", "keywords": "\"data evaluation, technological application\"\u003cSEP\u003e\"method application, pose estimation\"\u003cSEP\u003e\"pose recognition, dataset application\"", "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e\u003cSEP\u003echunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a\u003cSEP\u003echunk-a054a3e37bc1fcd86cb32715447f79a1", "to": "\"SAE\"", "width": 24.0}, {"description": "\"SAE provides a reliable decision confidence mechanism that enhances the performance of the SVM classifier in classification tasks.\"\u003cSEP\u003e\"SAE utilizes SVM for classification on the latent space, which results in improved accuracy over traditional approaches.\"", "from": "\"SAE\"", "keywords": "\"model enhancement, classification improvement\"\u003cSEP\u003e\"technology enhancement, classification accuracy\"", "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a\u003cSEP\u003echunk-a054a3e37bc1fcd86cb32715447f79a1", "to": "\"SVM\"", "width": 18.0}, {"description": "\"SAE offers improvements over Standard Autoencoders by providing clearer structure and better data separation in analysis.\"", "from": "\"SAE\"", "keywords": "\"comparison, methodological advancement\"", "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1", "to": "\"STANDARD AUTOENCODERS\"", "width": 8.0}, {"description": "\"SAE is assessed against Variational Autoencoders to showcase its advantages in structuring data and achieving clarity in classification.\"", "from": "\"SAE\"", "keywords": "\"methodological comparison, structural clarity\"", "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1", "to": "\"VARIATIONAL AUTOENCODERS\"", "width": 7.0}, {"description": "\"Adversarial Autoencoder is compared to SAE to showcase the latter\u0027s enhanced performance in classification tasks.\".\"", "from": "\"SAE\"", "keywords": "\"methodological comparison, performance assessment\"", "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1", "to": "\"ADVERSARIAL AUTOENCODER\"", "width": 8.0}, {"description": "\"SAE aims to enhance Decision Confidence by providing interpretable and reliable prediction scores.\".\"", "from": "\"SAE\"", "keywords": "\"model reliability, confidence metrics\"", "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1", "to": "\"DECISION CONFIDENCE\"", "width": 9.0}, {"description": "\"Guided Labeling utilizes the reliability of decisions made by the SAE to efficiently label important sample points, thereby improving training efficiency.\"", "from": "\"SAE\"", "keywords": "\"training efficiency, data labeling\"", "source_id": "chunk-3ae2925ca0a8a4c4599df3dd5cbb8f3a", "to": "\"GUIDED LABELING\"", "width": 9.0}, {"description": "\"The SAE may be improved by integrating Markov Chain Neural Networks to enhance classification and learning efficiency.\"", "from": "\"SAE\"", "keywords": "\"method enhancement, advanced techniques\"", "source_id": "chunk-25e488b3f3a1bc8c8ba9a749034b171e", "to": "\"MARKOV CHAIN NEURAL NETWORKS\"", "width": 7.0}, {"description": "\"CNN serves as a reference model compared to Standard Autoencoders in various classification scenarios.\".\"", "from": "\"STANDARD AUTOENCODERS\"", "keywords": "\"model comparison, classification tasks\"", "source_id": "chunk-a054a3e37bc1fcd86cb32715447f79a1", "to": "\"CNN\"", "width": 7.0}, {"description": "\"A. Carreira-Perpi\u00f1an is associated with the IEEE Conference on CVPR as an author, contributing to the discussions and findings presented at the event.\"", "from": "\"A. CARREIRA-PERPI\u00d1AN\"", "keywords": "\"research contribution, event participation\"", "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60", "to": "\"IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)\"", "width": 8.0}, {"description": "\"A. Carreira-Perpi\u00f1an\u0027s research extends to presentations at ICML, indicating active participation in the machine learning community.\"", "from": "\"A. CARREIRA-PERPI\u00d1AN\"", "keywords": "\"research contribution, event participation\"", "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60", "to": "\"INTERNATIONAL CONFERENCE ON MACHINE LEARNING (ICML)\"", "width": 7.0}, {"description": "\"R. Raziperchikolaei co-authors research presented at the IEEE Conference on CVPR, indicating their involvement in significant advancements in computer vision.\"", "from": "\"R. RAZIPERCHIKOLAEI\"", "keywords": "\"collaboration, research contribution\"", "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60", "to": "\"IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)\"", "width": 8.0}, {"description": "\"R. Raziperchikolaei is also involved in research discussed at ICML, contributing to the evolution of machine learning techniques.\"", "from": "\"R. RAZIPERCHIKOLAEI\"", "keywords": "\"collaboration, research contribution\"", "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60", "to": "\"INTERNATIONAL CONFERENCE ON MACHINE LEARNING (ICML)\"", "width": 7.0}, {"description": "\"ACM publishes substantial research findings from events like IEEE CVPR, emphasizing its role in the academic community.\"", "from": "\"IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR)\"", "keywords": "\"publishing, knowledge dissemination\"", "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60", "to": "\"ACM\"", "width": 9.0}, {"description": "\"CoRR hosts various research papers, including presentations made at ICML, showcasing the exchange of knowledge in machine learning.\"", "from": "\"INTERNATIONAL CONFERENCE ON MACHINE LEARNING (ICML)\"", "keywords": "\"repository, knowledge exchange\"", "source_id": "chunk-7f621f55aaa10556978c3ae269d56c60", "to": "\"CORR\"", "width": 9.0}, {"description": "\"J. Engel and C. Raffel are co-authors working together on the hierarchical latent vector model for music structure.\"", "from": "\"J. ENGEL\"", "keywords": "\"collaboration, co-authorship\"", "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c", "to": "\"C. RAFFEL\"", "width": 8.0}, {"description": "\"J. Engel and C. Hawthorne are co-authors in the study of music structure, indicating a collaborative effort.\"", "from": "\"J. ENGEL\"", "keywords": "\"collaboration, co-authorship\"", "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c", "to": "\"C. HAWTHORNE\"", "width": 8.0}, {"description": "\"C. Raffel and D. Eck are co-authors, contributing to the hierarchical latent vector model for music structure.\"", "from": "\"C. RAFFEL\"", "keywords": "\"collaboration, co-authorship\"", "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c", "to": "\"D. ECK\"", "width": 8.0}, {"description": "\"D. Eck and C. Hawthorne are part of the same research team focusing on hierarchical latent vector models in music.\"", "from": "\"C. HAWTHORNE\"", "keywords": "\"collaboration, co-authorship\"", "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c", "to": "\"D. ECK\"", "width": 8.0}, {"description": "\"The conference is held at Stockholmsm\u00a8assan, indicating the venue for academic discussions.\"", "from": "\"PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING\"", "keywords": "\"event venue, collaboration\"", "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c", "to": "\"STOCKHOLMSM\u00a8ASSAN\"", "width": 7.0}, {"description": "\"Machine Learning Research publishes the proceedings of the conference, playing an important role in disseminating scientific knowledge.\"", "from": "\"PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING\"", "keywords": "\"publication, knowledge dissemination\"", "source_id": "chunk-2d7c1c465da6845a22d14f73db6b298c", "to": "\"MACHINE LEARNING RESEARCH\"", "width": 9.0}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {
    "configure": {
        "enabled": true,
        "filter": [
            "physics"
        ]
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};

                  


                  
                  // if this network requires displaying the configure window,
                  // put it in its div
                  options.configure["container"] = document.getElementById("config");
                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  
                      network.on("stabilizationProgress", function(params) {
                          document.getElementById('loadingBar').removeAttribute("style");
                          var maxWidth = 496;
                          var minWidth = 20;
                          var widthFactor = params.iterations/params.total;
                          var width = Math.max(minWidth,maxWidth * widthFactor);
                          document.getElementById('bar').style.width = width + 'px';
                          document.getElementById('text').innerHTML = Math.round(widthFactor*100) + '%';
                      });
                      network.once("stabilizationIterationsDone", function() {
                          document.getElementById('text').innerHTML = '100%';
                          document.getElementById('bar').style.width = '496px';
                          document.getElementById('loadingBar').style.opacity = 0;
                          // really clean the dom element
                          setTimeout(function () {document.getElementById('loadingBar').style.display = 'none';}, 500);
                      });
                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>